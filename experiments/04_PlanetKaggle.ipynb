{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Experiment 04: Amazon Planet\n",
    "\n",
    "This experiment uses the data from the Kaggle competition [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/leaderboard). Here we use a pretrained ResNet50 model to generate the features from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "XGBoost version: 0.6\n",
      "LightGBM version: 0.1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "import pkg_resources\n",
    "from libs.planet_kaggle import read_images, chunks, labels_from, enrich_with_feature_encoding, get_file_count, to_multi_label_dict\n",
    "from libs.timer import Timer\n",
    "from libs.utils import get_number_processors\n",
    "import warnings\n",
    "from libs.loaders import load_planet_kaggle\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"XGBoost version: {}\".format(pkg_resources.get_distribution('xgboost').version))\n",
    "print(\"LightGBM version: {}\".format(pkg_resources.get_distribution('lightgbm').version))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MOUNT_POINT=/mnt/data\n"
     ]
    }
   ],
   "source": [
    "%env MOUNT_POINT=/mnt/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are loaded and featurised using a pretrained ResNet50 model available from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:libs.loaders:Reading in labels\n",
      "\n",
      "Featurising training images:   0%|          | 0/1094.0 [00:00<?, ?it/s]\u001b[A\n",
      "Featurising training images: 100%|██████████| 1094/1094.0 [09:04<00:00,  1.88it/s]\n",
      "Featurising validation images: 100%|██████████| 172/172.0 [01:25<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_planet_kaggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XGBoost vs LightGBM benchmark\n",
    "\n",
    "We will compare both libraries on speed and preformance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_processors = get_number_processors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use a one-v-rest. So each classifier will be responsible for determining whether the assigned tag applies to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_features, train_labels, validation_features):\n",
    "    n_classes = train_labels.shape[1]\n",
    "    y_val_pred = np.zeros((validation_features.shape[0], n_classes))\n",
    "    time_results = defaultdict(list)\n",
    "    for class_i in tqdm(range(n_classes)):\n",
    "        with Timer() as t:\n",
    "            model.fit(train_features, train_labels[:, class_i])\n",
    "        time_results['train_time'].append(t.interval)\n",
    "        \n",
    "        with Timer() as t:\n",
    "            y_val_pred[:, class_i] = model.predict(validation_features)\n",
    "        time_results['test_time'].append(t.interval)\n",
    "        \n",
    "    return y_val_pred, time_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': lambda y_true, y_pred: precision_score(y_true, y_pred, average='samples'),\n",
    "    'Recall': lambda y_true, y_pred: recall_score(y_true, y_pred, average='samples'),\n",
    "    'F1': lambda y_true, y_pred: f1_score(y_true, y_pred, average='samples'),\n",
    "}\n",
    "\n",
    "def classification_metrics(metrics, y_true, y_pred):\n",
    "    return {metric_name:metric(y_true, y_pred) for metric_name, metric in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3b0e7fdc82bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                          \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                          \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_processors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                          random_state=random_seed) \n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=7, \n",
    "                         learning_rate=0.1, \n",
    "                         scale_pos_weight=2,\n",
    "                         n_estimators=300,\n",
    "                         gamma=0.1,\n",
    "                         min_child_weight=1,\n",
    "                         reg_lambda=1,\n",
    "                         subsample=1,\n",
    "                         n_jobs=number_processors,\n",
    "                         random_state=random_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred, timing_results = train_and_validate(xgb_model, train_features, y_train, validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict['xgb']={\n",
    "    'train_time': np.sum(timing_results['train_time']),\n",
    "    'test_time': np.sum(timing_results['test_time']),\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          y_val, \n",
    "                                          threshold_prediction(y_val_pred, threshold=0.1)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xgb_hist_model = XGBClassifier(max_depth=0, \n",
    "                              learning_rate=0.1, \n",
    "                              scale_pos_weight=2,\n",
    "                              n_estimators=300,\n",
    "                              gamma=0.1,\n",
    "                              min_child_weight=1,\n",
    "                              reg_lambda=1,\n",
    "                              subsample=1,\n",
    "                              max_leaves=2**7,\n",
    "                              grow_policy='lossguide',\n",
    "                              tree_method='hist',\n",
    "                              n_jobs=number_processors,\n",
    "                              random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred, timing_results = train_and_validate(xgb_hist_model, train_features, y_train, validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict['xgb_hist']={\n",
    "    'train_time': np.sum(timing_results['train_time']),\n",
    "    'test_time': np.sum(timing_results['test_time']),\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          y_val, \n",
    "                                          threshold_prediction(y_val_pred, threshold=0.1)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(num_leaves=2**7, \n",
    "                           learning_rate=0.1, \n",
    "                           scale_pos_weight=2,\n",
    "                           n_estimators=300,\n",
    "                           min_split_gain=0.1,\n",
    "                           min_child_weight=1,\n",
    "                           reg_lambda=1,\n",
    "                           subsample=1,\n",
    "                           nthread=number_processors,\n",
    "                           seed=random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_val_pred, timing_results = train_and_validate(lgbm_model, train_features, y_train, validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict['lgbm']={\n",
    "    'train_time': np.sum(timing_results['train_time']),\n",
    "    'test_time': np.sum(timing_results['test_time']),\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          y_val, \n",
    "                                          threshold_prediction(y_val_pred, threshold=0.1)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
