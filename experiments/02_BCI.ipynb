{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Experiment 02: BCI\n",
    "\n",
    "This experiment uses a Brain Computer Interface dataset. The purpose is to try and predict when the participant is paying attention. The dataset consists of recordings from a number of electrodes placed over the scalp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, precision_score, recall_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier, XGBModel\n",
    "import matplotlib\n",
    "import json\n",
    "\n",
    "from libs.loaders import load_bci\n",
    "from libs.timer import Timer\n",
    "\n",
    "import os\n",
    "os.environ['MOUNT_POINT'] = '/strata'\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XGBoost vs LightGBM benchmarkÂ¶\n",
    "\n",
    "We will compare both libraries on speed and preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Below we define the modeling pipelines for our two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipeline_steps = [('scale', StandardScaler())]\n",
    "continuous_pipeline = Pipeline(steps=pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "featurisers = [('continuous', continuous_pipeline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xgb_clf_pipeline = Pipeline(steps=[('features', FeatureUnion(featurisers)),\n",
    "                                          ('clf', XGBClassifier(max_depth=3, \n",
    "                                                                learning_rate=0.1, \n",
    "                                                                scale_pos_weight=2,\n",
    "                                                                n_estimators=100,\n",
    "                                                                gamma=0.1,\n",
    "                                                                min_child_weight=1,\n",
    "                                                                reg_lambda=1,\n",
    "                                                                subsample=1\n",
    "                                                                ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_hist_clf_pipeline = Pipeline(steps=[('features', FeatureUnion(featurisers)),\n",
    "                                          ('clf', XGBClassifier(max_depth=0, \n",
    "                                                                learning_rate=0.1, \n",
    "                                                                scale_pos_weight=2,\n",
    "                                                                n_estimators=100,\n",
    "                                                                gamma=0.1,\n",
    "                                                                min_child_weight=1,\n",
    "                                                                reg_lambda=1,\n",
    "                                                                subsample=1,\n",
    "                                                                max_leaves=2**3,\n",
    "                                                                grow_policy='lossguide',\n",
    "                                                                tree_method='hist'\n",
    "                                                                ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lgbm_clf_pipeline = Pipeline(steps=[('features', FeatureUnion(featurisers)),\n",
    "                                          ('clf', LGBMClassifier(num_leaves=2**3, \n",
    "                                                                learning_rate=0.1, \n",
    "                                                                scale_pos_weight=2,\n",
    "                                                                n_estimators=100,\n",
    "                                                                min_split_gain=0.1,\n",
    "                                                                min_child_weight=1,\n",
    "                                                                reg_lambda=1,\n",
    "                                                                subsample=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dataset has been preprepared by extracting 800ms epochs from each channel. The data was then lowpass filtered at 18Hz and downsampled by a factor of 6. This results is a feature vector of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 472 ms, total: 2.66 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, X_test, y_test = load_bci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'AUC': roc_auc_score,\n",
    "    'F1': f1_score,\n",
    "}\n",
    "\n",
    "def classification_metrics(metrics, y_true, y_pred):\n",
    "    return {metric_name:metric(y_true, y_pred) for metric_name, metric in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_train:\n",
    "    xgb_clf_pipeline.fit(np.concatenate(X),np.concatenate(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_test:\n",
    "    y_pred = xgb_clf_pipeline.predict(np.concatenate(X_test))results_dict['xgb']={\n",
    "    'train_time': t_train.interval,\n",
    "    'test_time': t_test.interval,\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          np.concatenate(y_test), \n",
    "                                          y_pred) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict['xgb']={\n",
    "    'train_time': t_train.interval,\n",
    "    'test_time': t_test.interval,\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          np.concatenate(y_test), \n",
    "                                          y_pred) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_train:\n",
    "    xgb_hist_clf_pipeline.fit(np.concatenate(X),np.concatenate(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_test:\n",
    "    y_pred = xgb_hist_clf_pipeline.predict(np.concatenate(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dict['xgb_hist']={\n",
    "    'train_time': t_train.interval,\n",
    "    'test_time': t_test.interval,\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          np.concatenate(y_test), \n",
    "                                          y_pred) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_train:\n",
    "    lgbm_clf_pipeline.fit(np.concatenate(X),np.concatenate(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t_test:\n",
    "    y_pred = lgbm_clf_pipeline.predict(np.concatenate(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results_dict['lgbm']={\n",
    "    'train_time': t_train.interval,\n",
    "    'test_time': t_test.interval,\n",
    "    'performance': classification_metrics(metrics_dict, \n",
    "                                          np.concatenate(y_test), \n",
    "                                          y_pred) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lgbm\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.5348626373626374,\n",
      "            \"Accuracy\": 0.8802275008364001,\n",
      "            \"F1\": 0.13734939759036147,\n",
      "            \"Precision\": 0.5588235294117647,\n",
      "            \"Recall\": 0.0782967032967033\n",
      "        },\n",
      "        \"test_time\": 0.2883765400038101,\n",
      "        \"train_time\": 48.438655051999376\n",
      "    },\n",
      "    \"xgb\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.5277435897435897,\n",
      "            \"Accuracy\": 0.8812311809969889,\n",
      "            \"F1\": 0.11027568922305765,\n",
      "            \"Precision\": 0.6285714285714286,\n",
      "            \"Recall\": 0.06043956043956044\n",
      "        },\n",
      "        \"test_time\": 0.3469330469961278,\n",
      "        \"train_time\": 194.47922542299784\n",
      "    },\n",
      "    \"xgb_hist\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.536521978021978,\n",
      "            \"Accuracy\": 0.8810639009702241,\n",
      "            \"F1\": 0.14234016887816647,\n",
      "            \"Precision\": 0.5841584158415841,\n",
      "            \"Recall\": 0.08104395604395605\n",
      "        },\n",
      "        \"test_time\": 0.3389265519945184,\n",
      "        \"train_time\": 104.82167733401002\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Concept Drift\n",
    "Concept drift can occur across many domains and can be caused by many factors such as sensor drift, seasonality, regime change, etc. One of the ways to combat this is by retraining. If the cause for the drift is observable then it can be incorporated into the model. In this specific instance the cause for the drift is an increase in the impedance in the electrodes, fatigue as well as a number of other factors. These are not observable in the dataset so we will have to retrain the model at regular intervals and observe the difference in performance. This constant retraining can be costly especially with large datasets. Below we will compare XGBoost and LightGBM in a naive retraining scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _predict(model, X_test, y_test, auc_list, interval_list):\n",
    "    with Timer() as t:\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        auc_list.append(roc_auc_score(y_test, y_pred[:, 1]))\n",
    "    interval_list.append(t.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_train_retrain_comparison(model, X, y, X_test, y_test):\n",
    "    retrain_model = deepcopy(model)\n",
    "    historical_X = deepcopy(X.tolist())\n",
    "    historical_y = deepcopy(y.tolist())\n",
    "    train_auc = list()\n",
    "    retrain_auc = list()\n",
    "    test_interval = list()\n",
    "    retrain_test_interval = list()\n",
    "    retrain_interval = list()\n",
    "    \n",
    "    for X_test_run, y_test_run in  tqdm_notebook(zip(X_test, y_test), total=len(y_test)):\n",
    "        prev_model = deepcopy(retrain_model)\n",
    "        \n",
    "        _predict(model, X_test_run, y_test_run, train_auc, test_interval)\n",
    "        _predict(retrain_model, X_test_run, y_test_run, retrain_auc, retrain_test_interval)\n",
    "        \n",
    "        historical_X.append(X_test_run)\n",
    "        historical_y.append(y_test_run)\n",
    "\n",
    "        new_train_X  = np.concatenate(historical_X)\n",
    "        with Timer() as t:\n",
    "            retrain_model.fit(new_train_X, np.concatenate(historical_y))\n",
    "        retrain_interval.append(t.interval)    \n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'Test interval':test_interval,\n",
    "        'Retrain Test interval':retrain_test_interval,\n",
    "        'Retrain interval':retrain_interval,\n",
    "        'Train AUC':train_auc,\n",
    "        'Retrain AUC':retrain_auc\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = run_train_retrain_comparison(xgb_hist_clf_pipeline, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "retrain_results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "retrain_results_dict['xgb'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = run_train_retrain_comparison(lgbm_clf_pipeline, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "retrain_results_dict['lgbm'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# XGB Retrain Results\n",
    "ax=retrain_results_dict['xgb'][['Train AUC', 'Retrain AUC']].rolling(window=10).mean().plot(xlim=[8, 35], \n",
    "                                                                                            ylim=[.72, .82],\n",
    "                                                                                            fontsize=12,\n",
    "                                                                                            linewidth=4,\n",
    "                                                                                            figsize=(10,5),\n",
    "                                                                                            color=['#5975a4', '#a1bae3'])\n",
    "ax.set_ylabel('AUC', fontsize=16);\n",
    "ax.get_figure().savefig('xgb_retrain_results.svg', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Overall we can see that retraining does seem to help a bit. Ofcourse the retraining done here is naive with no consideration that later samples may also contain more noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# LGBM Retrain Results\n",
    "ax=retrain_results_dict['lgbm'][['Train AUC', 'Retrain AUC']].rolling(window=10).mean().plot(xlim=[8, 35],\n",
    "                                                                                             ylim=[.72, .82],\n",
    "                                                                                            fontsize=12,\n",
    "                                                                                            linewidth=4,\n",
    "                                                                                            figsize=(10,5),\n",
    "                                                                                            color=['#5f9e6f', '#a2cfae'])\n",
    "ax.set_ylabel('AUC', fontsize=16);\n",
    "ax.get_figure().savefig('lgbm_retrain_results.svg', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Retrainig does also seem to improve the results for the LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xgb_series = retrain_results_dict['xgb'][['Retrain Test interval', 'Retrain interval', 'Test interval']].sum()\n",
    "lgbm_series = retrain_results_dict['lgbm'][['Retrain Test interval', 'Retrain interval', 'Test interval']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=12) \n",
    "matplotlib.rc('ytick', labelsize=12) \n",
    "matplotlib.rcParams['figure.figsize'] = (6., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# XGB vs LGBM Retrain Time\n",
    "t_res = pd.DataFrame([['XGBoost', xgb_series['Retrain interval']/60],\n",
    "              ['LightGBM', lgbm_series['Retrain interval']/60]], columns=['Model', 'Time(m)'])\n",
    "ax = seaborn.barplot(x=\"Model\", y=\"Time(m)\", data=t_res)\n",
    "ax.set_ylabel('Time (min)', fontsize=16);\n",
    "ax.set_xlabel('');\n",
    "ax.get_figure().savefig('xgb_vs_lgbm_retrain_time.svg', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "LightGBM seems to be almost twice as fast as XGBoost and offer similar performance. In general, leaf-wise algorithms are more efficient and converge faster than depth-wise. However, it can easily over-fit when the data is small or the number of leaves is too high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "e447fa117d0f4cbba90bd677456c4000": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
