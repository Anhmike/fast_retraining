{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Experiment 01: Airline dataset\n",
    "\n",
    "In this experiment we use [the airline dataset](http://kt.ijs.si/elena_ikonomovska/data.html) to predict arrival delay. The dataset consists of a large amount of records, containing flight arrival and departure details for all the commercial flights within the USA, from October 1987 to April 2008. Its size is around 116 million records and 5.76 GB of memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "XGBoost version: 0.6\n",
      "LightGBM version: 0.2\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, roc_auc_score, f1_score, log_loss, precision_score,\n",
    "                             recall_score)\n",
    "from libs.loaders import load_airline\n",
    "from libs.conversion import convert_cols_categorical_to_numeric, convert_related_cols_categorical_to_numeric\n",
    "from libs.timer import Timer\n",
    "from libs.utils import get_number_processors\n",
    "from libs.notebook_memory_management import start_watching_memory\n",
    "import pkg_resources\n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"XGBoost version: {}\".format(pkg_resources.get_distribution('xgboost').version))\n",
    "print(\"LightGBM version: {}\".format(pkg_resources.get_distribution('lightgbm').version))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 9.7539 MiB RAM in 0.29s, peaked 0.00 MiB above current, total RAM usage 124.00 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.504199. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1) XGBoost vs LightGBM benchmark\n",
    "In the next section we compare both libraries speed, accuracy and other metrics for the dataset of airline arrival delay. \n",
    "\n",
    "### Data loading and management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOUNT_POINT not found in environment. Defaulting to /fileshare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.529082. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115069017, 14)\n",
      "CPU times: user 1min 36s, sys: 14.9 s, total: 1min 51s\n",
      "Wall time: 5min 16s\n",
      "In [3] used 21994.4492 MiB RAM in 317.01s, peaked 12290.76 MiB above current, total RAM usage 22118.45 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane = load_airline()\n",
    "print(df_plane.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.551778. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>AA</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>EA</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SFO</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>HP</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>ICT</td>\n",
       "      <td>LAS</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>DL</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>MCO</td>\n",
       "      <td>PBI</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>UA</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>LAS</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556            AA   \n",
       "1  1987     10           1          4           5         114            EA   \n",
       "2  1987     10           1          4           5          35            HP   \n",
       "3  1987     10           1          4           5          40            DL   \n",
       "4  1987     10           1          4           8         517            UA   \n",
       "\n",
       "   FlightNum  ActualElapsedTime Origin Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247    SFO  ORD      1846         0        27  \n",
       "1         57                 74    LAX  SFO       337         0         5  \n",
       "2        351                167    ICT  LAS       987         0        17  \n",
       "3        251                 35    MCO  PBI       142         0        -2  \n",
       "4        500                208    LAS  ORD      1515         0        17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [4] used 0.2188 MiB RAM in 0.40s, peaked 0.00 MiB above current, total RAM usage 22118.66 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first step is to convert the categorical features to numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.603459. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 7.75 s, total: 1min 49s\n",
      "Wall time: 1min 48s\n",
      "In [5] used 5269.6680 MiB RAM in 108.89s, peaked 0.00 MiB above current, total RAM usage 27388.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_related_cols_categorical_to_numeric(df_plane, col_list=['Origin','Dest'])\n",
    "del df_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.620527. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>AA</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>EA</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>HP</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>DL</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>UA</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556            AA   \n",
       "1  1987     10           1          4           5         114            EA   \n",
       "2  1987     10           1          4           5          35            HP   \n",
       "3  1987     10           1          4           5          40            DL   \n",
       "4  1987     10           1          4           8         517            UA   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247       0    33      1846         0        27  \n",
       "1         57                 74       1     0       337         0         5  \n",
       "2        351                167       2     4       987         0        17  \n",
       "3        251                 35       3    41       142         0        -2  \n",
       "4        500                208       4    33      1515         0        17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 0.0156 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 27388.35 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.688889. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 8.4 s, total: 1min 9s\n",
      "Wall time: 1min 9s\n",
      "In [7] used 12288.9062 MiB RAM in 69.50s, peaked 0.00 MiB above current, total RAM usage 39677.25 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_cols_categorical_to_numeric(df_plane_numeric, col_list='UniqueCarrier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.693215. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime  UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556              0   \n",
       "1  1987     10           1          4           5         114              1   \n",
       "2  1987     10           1          4           5          35              2   \n",
       "3  1987     10           1          4           5          40              3   \n",
       "4  1987     10           1          4           8         517              4   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247       0    33      1846         0        27  \n",
       "1         57                 74       1     0       337         0         5  \n",
       "2        351                167       2     4       987         0        17  \n",
       "3        251                 35       3    41       142         0        -2  \n",
       "4        500                208       4    33      1515         0        17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 0.0039 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 39677.26 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To simplify the pipeline, we are going to set a classification problem where the goal is to classify wheather a flight has arrived delayed or not. For that we need to binarize the variable `ArrDelay`.\n",
    "\n",
    "If you want to extend this experiment, you can set a regression problem and try to identify the number of minutes of delay a fight has. Both XGBoost and LightGBM have regression classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.700942. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 500 ms, sys: 480 ms, total: 980 ms\n",
      "Wall time: 662 ms\n",
      "In [9] used 877.9336 MiB RAM in 0.77s, peaked 770.41 MiB above current, total RAM usage 40555.19 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric['ArrDelayBinary'] = 1*(df_plane_numeric['ArrDelay'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.709710. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime  UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556              0   \n",
       "1  1987     10           1          4           5         114              1   \n",
       "2  1987     10           1          4           5          35              2   \n",
       "3  1987     10           1          4           5          40              3   \n",
       "4  1987     10           1          4           8         517              4   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \\\n",
       "0        190                247       0    33      1846         0        27   \n",
       "1         57                 74       1     0       337         0         5   \n",
       "2        351                167       2     4       987         0        17   \n",
       "3        251                 35       3    41       142         0        -2   \n",
       "4        500                208       4    33      1515         0        17   \n",
       "\n",
       "   ArrDelayBinary  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 0.0000 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 40555.19 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once the features are prepared, let's split the dataset into train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.717309. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 0.0195 MiB RAM in 0.17s, peaked 0.00 MiB above current, total RAM usage 40555.21 MiB\n"
     ]
    }
   ],
   "source": [
    "def split_train_val_test_df(df, val_size=0.2, test_size=0.2):\n",
    "    train, validate, test = np.split(df.sample(frac=1), \n",
    "                                     [int((1-val_size-test_size)*len(df)), int((1-test_size)*len(df))])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.724178. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69041410, 15)\n",
      "(23013803, 15)\n",
      "(23013804, 15)\n",
      "CPU times: user 52.5 s, sys: 36.9 s, total: 1min 29s\n",
      "Wall time: 1min 27s\n",
      "In [12] used 14039.7695 MiB RAM in 87.80s, peaked 26312.12 MiB above current, total RAM usage 54594.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, validate, test = split_train_val_test_df(df_plane_numeric)\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used 0.1367 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 54595.12 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.731640. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "def generate_feables(df):\n",
    "    X = df[df.columns.difference(['ArrDelay', 'ArrDelayBinary'])]\n",
    "    y = df['ArrDelayBinary']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.738837. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 2.75 s, total: 4.78 s\n",
      "Wall time: 4.7 s\n",
      "In [14] used 11412.8750 MiB RAM in 4.94s, peaked 0.00 MiB above current, total RAM usage 66007.99 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train = generate_feables(train)\n",
    "X_val, y_val = generate_feables(validate)\n",
    "X_test, y_test = generate_feables(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training \n",
    "Now we are going to create two pipelines, one of XGBoost and one for LightGBM. The technology behind both libraries is different, so it is difficult to compare them in the exact same model setting. XGBoost grows the trees depth-wise and controls model complexity with `max_depth`. Instead, LightGBM uses a leaf-wise algorithm and controls the model complexity by `num_leaves`. As a tradeoff, we use XGBoost with `max_depth=8`, which will have max number leaves of 255, and compare it with LightGBM with `num_leaves=255`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used -0.0156 MiB RAM in 0.10s, peaked 0.02 MiB above current, total RAM usage 66007.98 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.747804. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.757547. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "In [16] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 66007.98 MiB\n"
     ]
    }
   ],
   "source": [
    "number_processors = get_number_processors()\n",
    "print(number_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's start with the XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.763914. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.0000 MiB RAM in 0.21s, peaked 0.00 MiB above current, total RAM usage 66007.98 MiB\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_pipeline = XGBRegressor(max_depth=8,\n",
    "                                n_estimators=50,\n",
    "                                min_child_weight=30,\n",
    "                                learning_rate=0.1,\n",
    "                                colsample_bytree=0.80,\n",
    "                                scale_pos_weight=2,\n",
    "                                gamma=0.1,\n",
    "                                reg_lambda=1,\n",
    "                                subsample=1,\n",
    "                                n_jobs=number_processors,\n",
    "                                random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoaphumanoid/anaconda3/envs/strata2/lib/python3.6/site-packages/jupyter_client/jsonutil.py:67: DeprecationWarning: Interpreting naive datetime as local 2017-06-07 19:38:38.772070. Please add timezone info to timestamps.\n",
      "  new_obj[k] = extract_dates(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 17596.7969 MiB RAM in 1454.49s, peaked 1072.49 MiB above current, total RAM usage 83604.77 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    xgb_clf_pipeline.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [19] used 0.0664 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 83604.84 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training XGBoost model with leave-wise growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [20] used 0.0234 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 83604.86 MiB\n"
     ]
    }
   ],
   "source": [
    "xgb_hist_clf_pipeline = XGBRegressor(max_depth=0,\n",
    "                                    n_estimators=50,\n",
    "                                    min_child_weight=30,\n",
    "                                    learning_rate=0.1,\n",
    "                                    colsample_bytree=0.80,\n",
    "                                    scale_pos_weight=2,\n",
    "                                    gamma=0.1,\n",
    "                                    reg_lambda=1,\n",
    "                                    subsample=1,\n",
    "                                    max_leaves=255,\n",
    "                                    grow_policy='lossguide',\n",
    "                                    tree_method='hist',\n",
    "                                    n_jobs=number_processors,\n",
    "                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [21] used 20115.9141 MiB RAM in 537.86s, peaked 0.00 MiB above current, total RAM usage 103720.78 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    xgb_hist_clf_pipeline.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 0.0469 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 103720.82 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [23] used 0.0195 MiB RAM in 0.21s, peaked 0.00 MiB above current, total RAM usage 103720.84 MiB\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf_pipeline = LGBMRegressor(num_leaves=255,\n",
    "                                  n_estimators=50,\n",
    "                                  min_child_weight=30,\n",
    "                                  learning_rate=0.1,\n",
    "                                  colsample_bytree=0.80,\n",
    "                                  scale_pos_weight=2,\n",
    "                                  min_split_gain=0.1,\n",
    "                                  reg_lambda=1,\n",
    "                                  subsample=1,\n",
    "                                  nthread=number_processors,\n",
    "                                  seed=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [24] used 0.0078 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 103720.85 MiB\n"
     ]
    }
   ],
   "source": [
    "def loglikelood(y_true, y_pred):\n",
    "    eval_result = log_loss(y_true, y_pred)\n",
    "    eval_name = 'log_loss'\n",
    "    is_bigger_better = False\n",
    "    return eval_name, eval_result, is_bigger_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [25] used 3246.2734 MiB RAM in 756.52s, peaked 18369.75 MiB above current, total RAM usage 106967.12 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    lgbm_clf_pipeline.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, eval_metric=loglikelood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [26] used 0.0078 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 106967.13 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As it can be seen in the results, given the specific versions and parameters of both XGBoost and LightGBM and in this specific dataset, LightGBM is faster. \n",
    "\n",
    "In general terms, leaf-wise algorithms are more efficient, they converge much faster than depth-wise. However, it may cause over-fitting when the data is small or there are too many leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluation\n",
    "Now let's evaluate the model in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [27] used 199.4844 MiB RAM in 13.52s, peaked 7309.14 MiB above current, total RAM usage 107166.62 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb = np.clip(xgb_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [28] used -0.0781 MiB RAM in 0.10s, peaked 0.08 MiB above current, total RAM usage 107166.54 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [29] used 87.7930 MiB RAM in 14.07s, peaked 7556.39 MiB above current, total RAM usage 107254.33 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb_hist = np.clip(xgb_hist_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [30] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 107254.33 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [31] used 2458.0508 MiB RAM in 15.94s, peaked 4565.12 MiB above current, total RAM usage 109712.38 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_lgbm = np.clip(lgbm_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [32] used -0.0195 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 109712.36 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']['test_time'] = t.interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Metrics\n",
    "We are going to obtain some metrics to evaluate the performance of each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [33] used 0.0000 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 109712.36 MiB\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/miguelgfierro/codebase/blob/master/python/machine_learning/metrics.py\n",
    "def classification_metrics_binary(y_true, y_pred):\n",
    "    m_acc = accuracy_score(y_true, y_pred)\n",
    "    m_f1 = f1_score(y_true, y_pred)\n",
    "    m_precision = precision_score(y_true, y_pred)\n",
    "    m_recall = recall_score(y_true, y_pred)\n",
    "    report = {'Accuracy':m_acc, 'Precision':m_precision, 'Recall':m_recall, 'F1':m_f1}\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [34] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 109712.36 MiB\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/miguelgfierro/codebase/blob/master/python/machine_learning/metrics.py\n",
    "def classification_metrics_binary_prob(y_true, y_prob):\n",
    "    m_auc = roc_auc_score(y_true, y_prob)\n",
    "    report = {'AUC':m_auc}\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [35] used 0.0000 MiB RAM in 0.15s, peaked 0.00 MiB above current, total RAM usage 109712.36 MiB\n"
     ]
    }
   ],
   "source": [
    "def binarize_prediction(y, threshold=0.5):\n",
    "    y_pred = np.where(y > threshold, 1, 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [36] used 526.6523 MiB RAM in 0.59s, peaked 0.00 MiB above current, total RAM usage 110239.02 MiB\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = binarize_prediction(y_prob_xgb)\n",
    "y_pred_xgb_hist = binarize_prediction(y_prob_xgb_hist)\n",
    "y_pred_lgbm = binarize_prediction(y_prob_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.63131305889282796, 'Precision': 0.57093822694344398, 'Recall': 0.89887294790305039, 'F1': 0.6983222551383752, 'AUC': 0.78574591886297918}\n",
      "In [37] used -1764.3711 MiB RAM in 31.84s, peaked 1764.37 MiB above current, total RAM usage 108474.64 MiB\n"
     ]
    }
   ],
   "source": [
    "report_xgb = classification_metrics_binary(y_test, y_pred_xgb)\n",
    "report2_xgb = classification_metrics_binary_prob(y_test, y_prob_xgb)\n",
    "report_xgb.update(report2_xgb)\n",
    "print(report_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [38] used 0.0078 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 108474.65 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']['performance'] = report_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.67368510655604785, 'Precision': 0.60939772125982838, 'Recall': 0.87073064934943689, 'F1': 0.71699358526074042}\n",
      "In [39] used 13.9062 MiB RAM in 26.95s, peaked 730.49 MiB above current, total RAM usage 108488.56 MiB\n"
     ]
    }
   ],
   "source": [
    "report_xgb_hist = classification_metrics_binary(y_test, y_pred_xgb_hist)\n",
    "report2_xgb_hist = classification_metrics_binary_prob(y_test, y_prob_xgb_hist)\n",
    "report_xgb.update(report2_xgb_hist)\n",
    "print(report_xgb_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [40] used 0.0078 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 108488.57 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']['performance'] = report_xgb_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.7356018587800609, 'Precision': 0.769833914912471, 'Recall': 0.63200874453226463, 'F1': 0.69414604097567745, 'AUC': 0.80881583890120923}\n",
      "In [41] used 0.0117 MiB RAM in 28.01s, peaked 1199.01 MiB above current, total RAM usage 108488.58 MiB\n"
     ]
    }
   ],
   "source": [
    "report_lgbm = classification_metrics_binary(y_test, y_pred_lgbm)\n",
    "report2_lgbm = classification_metrics_binary_prob(y_test, y_prob_lgbm)\n",
    "report_lgbm.update(report2_lgbm)\n",
    "print(report_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [42] used 0.0078 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 108488.59 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']['performance'] = report_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lgbm\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.8088158389012092,\n",
      "            \"Accuracy\": 0.7356018587800609,\n",
      "            \"F1\": 0.6941460409756774,\n",
      "            \"Precision\": 0.769833914912471,\n",
      "            \"Recall\": 0.6320087445322646\n",
      "        },\n",
      "        \"test_time\": 15.899643832002766,\n",
      "        \"train_time\": 759.7789899049967\n",
      "    },\n",
      "    \"xgb\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.8078158817136188,\n",
      "            \"Accuracy\": 0.631313058892828,\n",
      "            \"F1\": 0.6983222551383752,\n",
      "            \"Precision\": 0.570938226943444,\n",
      "            \"Recall\": 0.8988729479030504\n",
      "        },\n",
      "        \"test_time\": 13.46883549899212,\n",
      "        \"train_time\": 1460.1219548319932\n",
      "    },\n",
      "    \"xgb_hist\": {\n",
      "        \"performance\": {\n",
      "            \"Accuracy\": 0.6736851065560479,\n",
      "            \"F1\": 0.7169935852607404,\n",
      "            \"Precision\": 0.6093977212598284,\n",
      "            \"Recall\": 0.8707306493494369\n",
      "        },\n",
      "        \"test_time\": 14.043752847996075,\n",
      "        \"train_time\": 540.0504210669897\n",
      "    }\n",
      "}\n",
      "In [43] used -0.0078 MiB RAM in 0.10s, peaked 0.01 MiB above current, total RAM usage 108488.58 MiB\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The experiment shows a fairly similar performance in both libraries, being LightGBM slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [44] used -51019.8906 MiB RAM in 1.39s, peaked 51019.83 MiB above current, total RAM usage 57468.69 MiB\n"
     ]
    }
   ],
   "source": [
    "del xgb_clf_pipeline, xgb_hist_clf_pipeline, lgbm_clf_pipeline, X_train, X_test, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2) Concept drift\n",
    "In this section we are trying to find concept drift in the dataset to check if retraining is valuable.\n",
    "\n",
    "### Data management\n",
    "We are going to pack the data yearly to try to find concept drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [45] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 57468.69 MiB\n"
     ]
    }
   ],
   "source": [
    "def get_data_list_yearly(df):\n",
    "    data_yearly = [df[df['Year'] == year] for year in range(1987, 2008)]  \n",
    "    return data_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287333, 15)\n",
      "(5126498, 15)\n",
      "(290827, 15)\n",
      "(5110527, 15)\n",
      "(4995005, 15)\n",
      "(5020651, 15)\n",
      "(4993587, 15)\n",
      "(5078411, 15)\n",
      "(5219140, 15)\n",
      "(5209326, 15)\n",
      "(5301999, 15)\n",
      "(5227051, 15)\n",
      "(5360018, 15)\n",
      "(5481303, 15)\n",
      "(5723673, 15)\n",
      "(5197860, 15)\n",
      "(6375689, 15)\n",
      "(6987729, 15)\n",
      "(6992838, 15)\n",
      "(7003802, 15)\n",
      "(7275288, 15)\n",
      "CPU times: user 8.61 s, sys: 3.78 s, total: 12.4 s\n",
      "Wall time: 12.3 s\n",
      "In [46] used 12753.6133 MiB RAM in 12.37s, peaked 0.00 MiB above current, total RAM usage 70222.30 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_yearly_list = get_data_list_yearly(df_plane_numeric)\n",
    "del(df_plane_numeric)\n",
    "for subset in data_yearly_list:\n",
    "    print(subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of years: 21\n",
      "In [47] used 0.0195 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 70222.32 MiB\n"
     ]
    }
   ],
   "source": [
    "total_subsets = len(data_yearly_list)\n",
    "print(\"Number of years: {}\".format(total_subsets))\n",
    "num_ini = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [48] used 0.0000 MiB RAM in 0.21s, peaked 0.00 MiB above current, total RAM usage 70222.32 MiB\n"
     ]
    }
   ],
   "source": [
    "def generate_subset(data_yearly_list, num):\n",
    "    subset = data_yearly_list[0]\n",
    "    for i in range(1,num):\n",
    "        subset = pd.concat([subset, data_yearly_list[i]])\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Traininig\n",
    "Let's see what happens when we train on a subset of data and then evaluate in the data of the following years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16810190, 15)\n",
      "CPU times: user 844 ms, sys: 1.4 s, total: 2.25 s\n",
      "Wall time: 2.23 s\n",
      "In [49] used 2052.0312 MiB RAM in 2.38s, peaked 1367.71 MiB above current, total RAM usage 72274.35 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_base = generate_subset(data_yearly_list, num_ini)\n",
    "print(subset_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [50] used 1667.1211 MiB RAM in 0.78s, peaked 0.00 MiB above current, total RAM usage 73941.47 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_feables(subset_base)\n",
    "del(subset_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [51] used 0.1523 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 73941.62 MiB\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier(num_leaves=255,\n",
    "                    n_estimators=100,\n",
    "                    min_child_weight=30,\n",
    "                    learning_rate=0.1,\n",
    "                    subsample=0.80,\n",
    "                    colsample_bytree=0.80,\n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 14s, sys: 26.9 s, total: 27min 41s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=30, min_split_gain=0, n_estimators=100,\n",
       "        nthread=-1, num_leaves=255, objective='binary', reg_alpha=0,\n",
       "        reg_lambda=0, seed=42, silent=True, subsample=0.8,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [52] used 2324.9062 MiB RAM in 86.83s, peaked 2821.04 MiB above current, total RAM usage 76266.53 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [53] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 76266.53 MiB\n"
     ]
    }
   ],
   "source": [
    "def predict_accuracy_future_years(clf, data_yearly_list, num_ini):\n",
    "    total_subsets = len(data_yearly_list)\n",
    "    accuracy_dict = {}\n",
    "    for y in range(num_ini, total_subsets):\n",
    "        year = data_yearly_list[y]['Year'].iloc[0]\n",
    "        print(\"Predicting year {}...\".format(year))\n",
    "        X_test, y_test = generate_feables(data_yearly_list[y])\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracy_dict[year] = acc\n",
    "    return accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting year 1992...\n",
      "Predicting year 1993...\n",
      "Predicting year 1994...\n",
      "Predicting year 1995...\n",
      "Predicting year 1996...\n",
      "Predicting year 1997...\n",
      "Predicting year 1998...\n",
      "Predicting year 1999...\n",
      "Predicting year 2000...\n",
      "Predicting year 2001...\n",
      "Predicting year 2002...\n",
      "Predicting year 2003...\n",
      "Predicting year 2004...\n",
      "Predicting year 2005...\n",
      "Predicting year 2006...\n",
      "Predicting year 2007...\n",
      "{1992: 0.75585058591007426, 1993: 0.75526209916839337, 1994: 0.7434018239169693, 1995: 0.73087711768605557, 1996: 0.72221396779544988, 1997: 0.72037697479761875, 1998: 0.705321030921642, 1999: 0.7002413051597961, 2000: 0.68913358739701125, 2001: 0.67351401800906519, 2002: 0.67900155063814727, 2003: 0.68467627577192047, 2004: 0.67967690218095178, 2005: 0.67261289336318097, 2006: 0.66322991426656552, 2007: 0.65105340159729763}\n",
      "CPU times: user 32min 56s, sys: 18.6 s, total: 33min 15s\n",
      "Wall time: 2min 19s\n",
      "In [54] used 3520.2695 MiB RAM in 139.70s, peaked 4292.78 MiB above current, total RAM usage 79786.80 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_dict = predict_accuracy_future_years(clf, data_yearly_list, num_ini)\n",
    "print(accuracy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the results we can observe that the accuracy of the model gets worse as the years pass on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Retraining\n",
    "Now let's see what happens when we retrain and evaluate in the data of the following years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [55] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 79786.80 MiB\n"
     ]
    }
   ],
   "source": [
    "new_init = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69425349, 15)\n",
      "CPU times: user 10.5 s, sys: 14.9 s, total: 25.4 s\n",
      "Wall time: 25.7 s\n",
      "In [61] used 8474.8086 MiB RAM in 25.77s, peaked 7596.57 MiB above current, total RAM usage 86869.39 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_retrain = generate_subset(data_yearly_list, new_init)\n",
    "print(subset_retrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [62] used 3172.1680 MiB RAM in 3.07s, peaked 0.00 MiB above current, total RAM usage 90041.56 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_feables(subset_retrain)\n",
    "del(subset_retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [63] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 90041.56 MiB\n"
     ]
    }
   ],
   "source": [
    "clf_retrain = LGBMClassifier(num_leaves=255,\n",
    "                    n_estimators=100,\n",
    "                    min_child_weight=30,\n",
    "                    learning_rate=0.1,\n",
    "                    subsample=0.80,\n",
    "                    colsample_bytree=0.80,\n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 39min 48s, sys: 5min 35s, total: 1h 45min 24s\n",
      "Wall time: 5min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=30, min_split_gain=0, n_estimators=100,\n",
       "        nthread=-1, num_leaves=255, objective='binary', reg_alpha=0,\n",
       "        reg_lambda=0, seed=42, silent=True, subsample=0.8,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [64] used 9787.2422 MiB RAM in 356.51s, peaked 12314.77 MiB above current, total RAM usage 99828.80 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_retrain.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting year 2002...\n",
      "Predicting year 2003...\n",
      "Predicting year 2004...\n",
      "Predicting year 2005...\n",
      "Predicting year 2006...\n",
      "Predicting year 2007...\n",
      "{2002: 0.75116624918716546, 2003: 0.74984397764696487, 2004: 0.72600969499532686, 2005: 0.72041222748188938, 2006: 0.70769504906049596, 2007: 0.69621175134235236}\n",
      "CPU times: user 10min 8s, sys: 2min 23s, total: 12min 32s\n",
      "Wall time: 51.1 s\n",
      "In [65] used 3951.0508 MiB RAM in 51.20s, peaked 2273.62 MiB above current, total RAM usage 103779.85 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_retrain = predict_accuracy_future_years(clf_retrain, data_yearly_list, new_init)\n",
    "print(accuracy_retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [68] used 0.1016 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 78568.90 MiB\n"
     ]
    }
   ],
   "source": [
    "def plot_metrics(metric1, metric2, legend1=None, legend2=None, x_label=None, y_label=None):\n",
    "    lists = sorted(metric1.items()) \n",
    "    x, y = zip(*lists) \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, label=legend1, color='#5975a4')\n",
    "    lists2 = sorted(metric2.items()) \n",
    "    x2, y2 = zip(*lists2) \n",
    "    ax.plot(x2, y2, label=legend2, color='#5f9e6f')\n",
    "    legend = ax.legend(loc=0)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAuGUkoph2jBUEop5RAtGEoppRzy/wEI2+FvqqzcnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f5df6ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [69] used 0.0000 MiB RAM in 0.41s, peaked 0.00 MiB above current, total RAM usage 78568.90 MiB\n"
     ]
    }
   ],
   "source": [
    "# Airline Retrain Results\n",
    "ax = plot_metrics(accuracy_dict, accuracy_retrain, legend1='Accuracy train', legend2='Accuracy retrain', x_label='year', \n",
    "             y_label='Accuracy')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('airline.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As it can be seen, the performance is better after retraining. We have found concept drift in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Strata2",
   "language": "python",
   "name": "strata2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
