{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 01: Airline dataset\n",
    "\n",
    "In this experiment we use [the airline dataset](http://kt.ijs.si/elena_ikonomovska/data.html) to predict arrival delay. The dataset consists of a large amount of records, containing flight arrival and departure details for all the commercial flights within the USA, from October 1987 to April 2008. Its size is around 116 million records and 5.76 GB of memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "XGBoost version: 0.6\n",
      "LightGBM version: 0.2\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, roc_auc_score, f1_score, log_loss, precision_score,\n",
    "                             recall_score)\n",
    "from libs.loaders import load_airline\n",
    "from libs.conversion import convert_cols_categorical_to_numeric, convert_related_cols_categorical_to_numeric\n",
    "from libs.timer import Timer\n",
    "from libs.utils import get_number_processors\n",
    "from libs.notebook_memory_management import start_watching_memory\n",
    "import pkg_resources\n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "from toolz import curry\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"XGBoost version: {}\".format(pkg_resources.get_distribution('xgboost').version))\n",
    "print(\"LightGBM version: {}\".format(pkg_resources.get_distribution('lightgbm').version))\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use in this notebook is huge, therefore we want to monitor the memory consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 12.2734 MiB RAM in 6.22s, total RAM usage 220.41 MiB\n"
     ]
    }
   ],
   "source": [
    "start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) XGBoost vs LightGBM benchmark\n",
    "In the next section we compare both libraries speed, accuracy and other metrics for the dataset of airline arrival delay. \n",
    "\n",
    "### Data loading and management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:libs.loaders:MOUNT_POINT not found in environment. Defaulting to /fileshare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115069017, 14)\n",
      "CPU times: user 1min 32s, sys: 17.7 s, total: 1min 50s\n",
      "Wall time: 4min 30s\n",
      "In [4] used 21994.8516 MiB RAM in 271.08s, total RAM usage 22215.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane = load_airline()\n",
    "print(df_plane.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>AA</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>EA</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SFO</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>HP</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>ICT</td>\n",
       "      <td>LAS</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>DL</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>MCO</td>\n",
       "      <td>PBI</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>UA</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>LAS</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556            AA   \n",
       "1  1987     10           1          4           5         114            EA   \n",
       "2  1987     10           1          4           5          35            HP   \n",
       "3  1987     10           1          4           5          40            DL   \n",
       "4  1987     10           1          4           8         517            UA   \n",
       "\n",
       "   FlightNum  ActualElapsedTime Origin Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247    SFO  ORD      1846         0        27  \n",
       "1         57                 74    LAX  SFO       337         0         5  \n",
       "2        351                167    ICT  LAS       987         0        17  \n",
       "3        251                 35    MCO  PBI       142         0        -2  \n",
       "4        500                208    LAS  ORD      1515         0        17  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.3242 MiB RAM in 0.12s, total RAM usage 22215.59 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to convert the categorical features to numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 13.8 s, total: 1min 50s\n",
      "Wall time: 1min 52s\n",
      "In [7] used 5270.3164 MiB RAM in 112.59s, total RAM usage 27485.91 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_related_cols_categorical_to_numeric(df_plane, col_list=['Origin','Dest'])\n",
    "del df_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>AA</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>EA</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>HP</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>DL</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>UA</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556            AA   \n",
       "1  1987     10           1          4           5         114            EA   \n",
       "2  1987     10           1          4           5          35            HP   \n",
       "3  1987     10           1          4           5          40            DL   \n",
       "4  1987     10           1          4           8         517            UA   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247       0    33      1846         0        27  \n",
       "1         57                 74       1     0       337         0         5  \n",
       "2        351                167       2     4       987         0        17  \n",
       "3        251                 35       3    41       142         0        -2  \n",
       "4        500                208       4    33      1515         0        17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 0.0039 MiB RAM in 0.12s, total RAM usage 27485.91 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 10.4 s, total: 1min 6s\n",
      "Wall time: 1min 7s\n",
      "In [9] used 13168.8945 MiB RAM in 68.02s, total RAM usage 40654.80 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_cols_categorical_to_numeric(df_plane_numeric, col_list='UniqueCarrier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime  UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556              0   \n",
       "1  1987     10           1          4           5         114              1   \n",
       "2  1987     10           1          4           5          35              2   \n",
       "3  1987     10           1          4           5          40              3   \n",
       "4  1987     10           1          4           8         517              4   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \n",
       "0        190                247       0    33      1846         0        27  \n",
       "1         57                 74       1     0       337         0         5  \n",
       "2        351                167       2     4       987         0        17  \n",
       "3        251                 35       3    41       142         0        -2  \n",
       "4        500                208       4    33      1515         0        17  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 0.0078 MiB RAM in 0.12s, total RAM usage 40654.81 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the pipeline, we are going to set a classification problem where the goal is to classify wheather a flight has arrived delayed or not. For that we need to binarize the variable `ArrDelay`.\n",
    "\n",
    "If you want to extend this experiment, you can set a regression problem and try to identify the number of minutes of delay a fight has. Both XGBoost and LightGBM have regression classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 ms, sys: 400 ms, total: 956 ms\n",
      "Wall time: 955 ms\n",
      "In [11] used 877.9102 MiB RAM in 1.06s, total RAM usage 41532.72 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_plane_numeric['ArrDelayBinary'] = 1*(df_plane_numeric['ArrDelay'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayofWeek  CRSDepTime  CRSArrTime  UniqueCarrier  \\\n",
       "0  1987     10           1          4           1         556              0   \n",
       "1  1987     10           1          4           5         114              1   \n",
       "2  1987     10           1          4           5          35              2   \n",
       "3  1987     10           1          4           5          40              3   \n",
       "4  1987     10           1          4           8         517              4   \n",
       "\n",
       "   FlightNum  ActualElapsedTime  Origin  Dest  Distance  Diverted  ArrDelay  \\\n",
       "0        190                247       0    33      1846         0        27   \n",
       "1         57                 74       1     0       337         0         5   \n",
       "2        351                167       2     4       987         0        17   \n",
       "3        251                 35       3    41       142         0        -2   \n",
       "4        500                208       4    33      1515         0        17   \n",
       "\n",
       "   ArrDelayBinary  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used -5267.4570 MiB RAM in 0.13s, total RAM usage 36265.27 MiB\n"
     ]
    }
   ],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the features are prepared, let's split the dataset into train and test set. We won't use validation for this example (however, you can try to add it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used 0.0000 MiB RAM in 0.10s, total RAM usage 36265.27 MiB\n"
     ]
    }
   ],
   "source": [
    "def split_train_val_test_df(df, val_size=0.2, test_size=0.2):\n",
    "    train, validate, test = np.split(df.sample(frac=1), \n",
    "                                     [int((1-val_size-test_size)*len(df)), int((1-test_size)*len(df))])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92055213, 15)\n",
      "(0, 15)\n",
      "(23013804, 15)\n",
      "CPU times: user 43.9 s, sys: 38.9 s, total: 1min 22s\n",
      "Wall time: 1min 24s\n",
      "In [14] used 10518.2578 MiB RAM in 84.82s, total RAM usage 46783.52 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, validate, test = split_train_val_test_df(df_plane_numeric, val_size=0, test_size=0.2)\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used 0.5703 MiB RAM in 0.10s, total RAM usage 46784.09 MiB\n"
     ]
    }
   ],
   "source": [
    "def generate_feables(df):\n",
    "    X = df[df.columns.difference(['ArrDelay', 'ArrDelayBinary'])]\n",
    "    y = df['ArrDelayBinary']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 2.46 s, total: 4.6 s\n",
      "Wall time: 4.66 s\n",
      "In [16] used 9131.0234 MiB RAM in 4.76s, total RAM usage 55915.12 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train = generate_feables(train)\n",
    "X_val, y_val = generate_feables(validate)\n",
    "X_test, y_test = generate_feables(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.0000 MiB RAM in 0.10s, total RAM usage 55915.12 MiB\n"
     ]
    }
   ],
   "source": [
    "del train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "Now we are going to create two pipelines, one of XGBoost and one for LightGBM. The technology behind both libraries is different, so it is difficult to compare them in the exact same model setting. XGBoost grows the trees depth-wise and controls model complexity with `max_depth`. Instead, LightGBM uses a leaf-wise algorithm and controls the model complexity by `num_leaves`. As a tradeoff, we use XGBoost with `max_depth=8`, which will have max number leaves of 255, and compare it with LightGBM with `num_leaves=255`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 0.0000 MiB RAM in 0.10s, total RAM usage 55915.12 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "In [19] used 0.0000 MiB RAM in 0.10s, total RAM usage 55915.12 MiB\n"
     ]
    }
   ],
   "source": [
    "number_processors = get_number_processors()\n",
    "print(number_processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start with the XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [20] used 0.0039 MiB RAM in 0.20s, total RAM usage 55915.12 MiB\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_pipeline = XGBRegressor(max_depth=8,\n",
    "                                n_estimators=50,\n",
    "                                min_child_weight=30,\n",
    "                                learning_rate=0.1,\n",
    "                                colsample_bytree=0.80,\n",
    "                                scale_pos_weight=2,\n",
    "                                gamma=0.1,\n",
    "                                reg_lambda=1,\n",
    "                                subsample=1,\n",
    "                                n_jobs=number_processors,\n",
    "                                random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [21] used 18443.2852 MiB RAM in 1852.67s, total RAM usage 74358.41 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    xgb_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 0.2500 MiB RAM in 0.10s, total RAM usage 74358.66 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training XGBoost model with leave-wise growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [23] used 0.0000 MiB RAM in 0.10s, total RAM usage 74358.66 MiB\n"
     ]
    }
   ],
   "source": [
    "xgb_hist_clf_pipeline = XGBRegressor(max_depth=0,\n",
    "                                    n_estimators=50,\n",
    "                                    min_child_weight=30,\n",
    "                                    learning_rate=0.1,\n",
    "                                    colsample_bytree=0.80,\n",
    "                                    scale_pos_weight=2,\n",
    "                                    gamma=0.1,\n",
    "                                    reg_lambda=1,\n",
    "                                    subsample=1,\n",
    "                                    max_leaves=255,\n",
    "                                    grow_policy='lossguide',\n",
    "                                    tree_method='hist',\n",
    "                                    n_jobs=number_processors,\n",
    "                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [24] used 23247.5430 MiB RAM in 595.04s, total RAM usage 97606.20 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    xgb_hist_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [25] used 0.2109 MiB RAM in 0.10s, total RAM usage 97606.41 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [26] used 0.0000 MiB RAM in 0.10s, total RAM usage 97606.41 MiB\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf_pipeline = LGBMRegressor(num_leaves=255,\n",
    "                                  n_estimators=50,\n",
    "                                  min_child_weight=30,\n",
    "                                  learning_rate=0.1,\n",
    "                                  colsample_bytree=0.80,\n",
    "                                  scale_pos_weight=2,\n",
    "                                  min_split_gain=0.1,\n",
    "                                  reg_lambda=1,\n",
    "                                  subsample=1,\n",
    "                                  nthread=number_processors,\n",
    "                                  seed=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [27] used 12295.2539 MiB RAM in 511.70s, total RAM usage 109901.66 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    lgbm_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [29] used 0.0000 MiB RAM in 0.16s, total RAM usage 109901.85 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']={\n",
    "    'train_time': t.interval\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen in the results, given the specific versions and parameters of both XGBoost and LightGBM and in this specific dataset, LightGBM is faster. \n",
    "\n",
    "In general terms, leaf-wise algorithms are more efficient, they converge much faster than depth-wise. However, it may cause over-fitting when the data is small or there are too many leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Now let's evaluate the model in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [30] used 175.6758 MiB RAM in 13.46s, total RAM usage 110077.53 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb = np.clip(xgb_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [31] used -9130.1641 MiB RAM in 0.10s, total RAM usage 100947.36 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [32] used 87.8125 MiB RAM in 15.95s, total RAM usage 101035.18 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb_hist = np.clip(xgb_hist_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [33] used 0.0000 MiB RAM in 0.10s, total RAM usage 101035.18 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [34] used 2458.2109 MiB RAM in 16.61s, total RAM usage 103493.39 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_lgbm = np.clip(lgbm_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [35] used 0.0312 MiB RAM in 0.10s, total RAM usage 103493.42 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']['test_time'] = t.interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "We are going to obtain some metrics to evaluate the performance of each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [36] used 0.0000 MiB RAM in 0.10s, total RAM usage 103493.42 MiB\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/miguelgfierro/codebase/blob/master/python/machine_learning/metrics.py\n",
    "def classification_metrics_binary(y_true, y_pred):\n",
    "    m_acc = accuracy_score(y_true, y_pred)\n",
    "    m_f1 = f1_score(y_true, y_pred)\n",
    "    m_precision = precision_score(y_true, y_pred)\n",
    "    m_recall = recall_score(y_true, y_pred)\n",
    "    report = {'Accuracy':m_acc, 'Precision':m_precision, 'Recall':m_recall, 'F1':m_f1}\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [37] used 0.0000 MiB RAM in 0.10s, total RAM usage 103493.42 MiB\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/miguelgfierro/codebase/blob/master/python/machine_learning/metrics.py\n",
    "def classification_metrics_binary_prob(y_true, y_prob):\n",
    "    m_auc = roc_auc_score(y_true, y_prob)\n",
    "    report = {'AUC':m_auc}\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [38] used 0.0000 MiB RAM in 0.10s, total RAM usage 103493.42 MiB\n"
     ]
    }
   ],
   "source": [
    "def binarize_prediction(y, threshold=0.5):\n",
    "    y_pred = np.where(y > threshold, 1, 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [39] used 526.6562 MiB RAM in 0.60s, total RAM usage 104020.07 MiB\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = binarize_prediction(y_prob_xgb)\n",
    "y_pred_xgb_hist = binarize_prediction(y_prob_xgb_hist)\n",
    "y_pred_lgbm = binarize_prediction(y_prob_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [40] used 534.1289 MiB RAM in 31.88s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "report_xgb = classification_metrics_binary(y_test, y_pred_xgb)\n",
    "report2_xgb = classification_metrics_binary_prob(y_test, y_prob_xgb)\n",
    "report_xgb.update(report2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [41] used 0.0000 MiB RAM in 0.10s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb']['performance'] = report_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [42] used 0.0000 MiB RAM in 27.09s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "report_xgb_hist = classification_metrics_binary(y_test, y_pred_xgb_hist)\n",
    "report2_xgb_hist = classification_metrics_binary_prob(y_test, y_prob_xgb_hist)\n",
    "report_xgb_hist.update(report2_xgb_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [43] used 0.0000 MiB RAM in 0.10s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['xgb_hist']['performance'] = report_xgb_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [44] used 0.0000 MiB RAM in 27.60s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "report_lgbm = classification_metrics_binary(y_test, y_pred_lgbm)\n",
    "report2_lgbm = classification_metrics_binary_prob(y_test, y_prob_lgbm)\n",
    "report_lgbm.update(report2_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [45] used 0.0000 MiB RAM in 0.10s, total RAM usage 104554.20 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict['lgbm']['performance'] = report_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lgbm\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.8087345269327301,\n",
      "            \"Accuracy\": 0.735365392005598,\n",
      "            \"F1\": 0.693742263725405,\n",
      "            \"Precision\": 0.7698017644571464,\n",
      "            \"Recall\": 0.63136124169849\n",
      "        },\n",
      "        \"test_time\": 16.278497151011834,\n",
      "        \"train_time\": 505.5069723850029\n",
      "    },\n",
      "    \"xgb\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.7861648512420553,\n",
      "            \"Accuracy\": 0.632291732388092,\n",
      "            \"F1\": 0.6988089123079965,\n",
      "            \"Precision\": 0.5717217499313083,\n",
      "            \"Recall\": 0.8985451545944861\n",
      "        },\n",
      "        \"test_time\": 13.243474364004214,\n",
      "        \"train_time\": 1821.469936723006\n",
      "    },\n",
      "    \"xgb_hist\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.8078543079265786,\n",
      "            \"Accuracy\": 0.6744731118766806,\n",
      "            \"F1\": 0.7173539975918762,\n",
      "            \"Precision\": 0.6102002842130803,\n",
      "            \"Recall\": 0.8701572351164102\n",
      "        },\n",
      "        \"test_time\": 15.677170230002957,\n",
      "        \"train_time\": 586.8677485149965\n",
      "    }\n",
      "}\n",
      "In [46] used -2282.5586 MiB RAM in 0.11s, total RAM usage 102271.64 MiB\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment shows a fairly similar performance in both libraries, being LightGBM slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [47] used -53454.2227 MiB RAM in 1.56s, total RAM usage 48817.42 MiB\n"
     ]
    }
   ],
   "source": [
    "del xgb_clf_pipeline, xgb_hist_clf_pipeline, lgbm_clf_pipeline, X_train, X_test, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2) Concept drift\n",
    "In this section we are trying to find concept drift in the dataset to check if retraining is valuable.\n",
    "\n",
    "### Data management\n",
    "We are going to pack the data yearly to try to find concept drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [48] used 0.0000 MiB RAM in 0.10s, total RAM usage 48817.42 MiB\n"
     ]
    }
   ],
   "source": [
    "initial_year = 1987\n",
    "num_ini = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [50] used 0.0625 MiB RAM in 0.10s, total RAM usage 48817.48 MiB\n"
     ]
    }
   ],
   "source": [
    "def generate_subset_by_year(df, year_ini, year_end):\n",
    "    return df[df['Year'].isin(range(year_ini, year_end))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16810190, 15)\n",
      "CPU times: user 1.73 s, sys: 8 ms, total: 1.74 s\n",
      "Wall time: 1.78 s\n",
      "In [51] used 0.1367 MiB RAM in 1.88s, total RAM usage 48817.62 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_base = generate_subset_by_year(df_plane_numeric, initial_year, initial_year + num_ini)\n",
    "print(subset_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98258827, 15)\n",
      "CPU times: user 1min 14s, sys: 6.2 s, total: 1min 20s\n",
      "Wall time: 1min 21s\n",
      "In [53] used 17114.7461 MiB RAM in 81.71s, total RAM usage 65932.62 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rest_df = df_plane_numeric.loc[df_plane_numeric.index.difference(subset_base.index)]\n",
    "print(rest_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig\n",
    "Let's see what happens when we train on a subset of data and then evaluate in the data of the following years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [54] used -8867.6094 MiB RAM in 1.05s, total RAM usage 57065.02 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_feables(subset_base)\n",
    "del(subset_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [55] used 0.0000 MiB RAM in 0.10s, total RAM usage 57065.02 MiB\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier(num_leaves=255,\n",
    "                    n_estimators=100,\n",
    "                    min_child_weight=30,\n",
    "                    learning_rate=0.1,\n",
    "                    subsample=0.80,\n",
    "                    colsample_bytree=0.80,\n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 26s, sys: 23 s, total: 24min 49s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=30, min_split_gain=0, n_estimators=100,\n",
       "        nthread=-1, num_leaves=255, objective='binary', reg_alpha=0,\n",
       "        reg_lambda=0, seed=42, silent=True, subsample=0.8,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [56] used 1676.8320 MiB RAM in 79.21s, total RAM usage 58741.85 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [57] used 0.0000 MiB RAM in 0.10s, total RAM usage 58741.85 MiB\n"
     ]
    }
   ],
   "source": [
    "@curry\n",
    "def predict_accuracy(clf, test_df):\n",
    "    X_test, y_test = generate_feables(test_df)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "1992    0.755851\n",
      "1993    0.755262\n",
      "1994    0.743402\n",
      "1995    0.730882\n",
      "1996    0.722218\n",
      "1997    0.720393\n",
      "1998    0.705346\n",
      "1999    0.700259\n",
      "2000    0.689137\n",
      "2001    0.673514\n",
      "2002    0.679002\n",
      "2003    0.684676\n",
      "2004    0.679677\n",
      "2005    0.672613\n",
      "2006    0.663230\n",
      "2007    0.651053\n",
      "2008    0.635933\n",
      "dtype: float64\n",
      "CPU times: user 35min 12s, sys: 1min 27s, total: 36min 40s\n",
      "Wall time: 2min 34s\n",
      "In [58] used 18055.7109 MiB RAM in 154.14s, total RAM usage 76797.56 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_series = rest_df.groupby('Year').apply(predict_accuracy(clf))\n",
    "print(accuracy_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we can observe that the accuracy of the model gets worse as the years pass on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining\n",
    "Now let's see what happens when we retrain and evaluate in the data of the following years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [59] used 0.0000 MiB RAM in 0.10s, total RAM usage 76797.56 MiB\n"
     ]
    }
   ],
   "source": [
    "new_init = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69425349, 15)\n",
      "CPU times: user 4.96 s, sys: 3.66 s, total: 8.61 s\n",
      "Wall time: 8.73 s\n",
      "In [66] used 8474.7227 MiB RAM in 8.84s, total RAM usage 113458.84 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset_retrain = generate_subset_by_year(df_plane_numeric, initial_year, initial_year + new_init) \n",
    "print(subset_retrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [61] used 5193.6953 MiB RAM in 11.50s, total RAM usage 89936.24 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_feables(subset_retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [62] used 0.0000 MiB RAM in 0.10s, total RAM usage 89936.24 MiB\n"
     ]
    }
   ],
   "source": [
    "clf_retrain = LGBMClassifier(num_leaves=255,\n",
    "                            n_estimators=100,\n",
    "                            min_child_weight=30,\n",
    "                            learning_rate=0.1,\n",
    "                            subsample=0.80,\n",
    "                            colsample_bytree=0.80,\n",
    "                            seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 35min 27s, sys: 1min 33s, total: 1h 37min 1s\n",
      "Wall time: 5min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=30, min_split_gain=0, n_estimators=100,\n",
       "        nthread=-1, num_leaves=255, objective='binary', reg_alpha=0,\n",
       "        reg_lambda=0, seed=42, silent=True, subsample=0.8,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [63] used 7946.2539 MiB RAM in 322.92s, total RAM usage 97882.49 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_retrain.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45643668, 15)\n",
      "CPU times: user 31.5 s, sys: 6.83 s, total: 38.4 s\n",
      "Wall time: 38.8 s\n",
      "In [67] used -5910.6914 MiB RAM in 38.93s, total RAM usage 107548.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rest_df = df_plane_numeric.loc[df_plane_numeric.index.difference(subset_retrain.index)]\n",
    "print(rest_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2002    0.751166\n",
      "2003    0.749844\n",
      "2004    0.726010\n",
      "2005    0.720412\n",
      "2006    0.707695\n",
      "2007    0.696212\n",
      "2008    0.699735\n",
      "dtype: float64\n",
      "CPU times: user 16min 10s, sys: 21.8 s, total: 16min 32s\n",
      "Wall time: 1min 15s\n",
      "In [75] used 10614.3203 MiB RAM in 75.32s, total RAM usage 82921.84 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_retrain = rest_df.groupby('Year').apply(predict_accuracy(clf_retrain))\n",
    "print(accuracy_retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [68] used -22750.0078 MiB RAM in 0.62s, total RAM usage 84798.14 MiB\n"
     ]
    }
   ],
   "source": [
    "def plot_metrics(metric1, metric2, legend1=None, legend2=None, x_label=None, y_label=None):\n",
    "    lists = sorted(metric1.items()) \n",
    "    x, y = zip(*lists) \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, label=legend1, color='#5975a4')\n",
    "    lists2 = sorted(metric2.items()) \n",
    "    x2, y2 = zip(*lists2) \n",
    "    ax.plot(x2, y2, label=legend2, color='#5f9e6f')\n",
    "    legend = ax.legend(loc=0)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Airline Retrain Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f210040dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [76] used -10613.6328 MiB RAM in 0.47s, total RAM usage 72308.20 MiB\n"
     ]
    }
   ],
   "source": [
    "# Airline Retrain Results\n",
    "ax = plot_metrics(accuracy_series.to_dict(), accuracy_retrain.to_dict(), legend1='Accuracy train', \n",
    "                  legend2='Accuracy retrain', x_label='year', y_label='Accuracy')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('airline.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the performance is better after retraining. We have found concept drift in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
